* 监督学习(supervised)
** 本质
通过一系列输入输出对学习，对一个新的输入给出对应的输出。
** 分类
 回归(regression)：在无穷可能的输出中，预测一个数字。
 分类(classificaton)：在有穷可能的输出(catgories/classes)中，预测一个类别。
** 术语
 训练集，输入变量/特征x，输出变量/目标y，训练集的总数m，单个训练样例(x,y)，预测y-hat;
** 工作过程
 训练集->学习算法->特定函数f

 **以下是单元的情况**
*** 成本函数(cost function)
 预测与实际值的偏差，目标是让这个函数最小化
 e.g. J=(yhat-y)^2,yhat=w x+b,我们要调整w和b使J最小(J是w,b的函数)
*** 梯度下降
 1. 猜测一个特定(w,b)
 2. 沿梯度方向修改(w,b)来减小J
 这个方法的最终结果是达到一个局部最小值

 具体更新：
 w=w- a dJ(w,b)/dw a称之为学习率通常在0到1间
 b=b- a dJ(w,b)/db
 快速理解，导数大于零时要后退来变小；小于零时前进来减小

 学习率太小，效率低；学习率太大，过冲振荡发散

 向量化：多用向量化运算的库如np.dot，简洁代码，并行加速运算 多用numpy

 **在多元的情况下**
 
* 非监督学习(unsupervised)
** 本质
 寻找一个没有标签的数据集中的特点、结构：不知道这些数据有什么特征/没有特定的输出值
** 分类
 聚类(clustering)：把相似的数据放到一起
 异常检测：
 降维：
